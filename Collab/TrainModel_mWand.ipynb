{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **THE EMBEDDED ML-WAND PROJECT**"
      ],
      "metadata": {
        "id": "lWUSug15g0q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This project involved developing a machine learning model for gesture recognition based on movement data captured by an IMU (Inertial Measurement Unit). The data, consisting of accelerometer and gyroscope readings, was processed and normalized to feed into a neural network built using TensorFlow. The neural network, consisting of dense layers with dropout and regularization, was trained to classify different gestures, and its architecture was optimized for performance and efficiency. Once trained, the model was converted into a TensorFlow Lite format suitable for deployment on an Arduino board. The final stage involved implementing an Arduino sketch to process real-time IMU data, perform inference using the trained model, and recognize gestures, thereby bridging the gap between machine learning and embedded systems in a real-world application.\n",
        "\n",
        "[Link to the video](https://youtu.be/CpNBOYuhglQ)\n",
        "\n",
        "Sources to be considered wihtin this project:\n",
        "\n",
        "[1] TensorFlow Authors, \"TensorFlow Core v2.9.0 Guide,\" 2023. [Online]. Available: https://www.tensorflow.org/guide.\n",
        "\n",
        "[2] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning, MIT Press, 2016. [Online]. Available: http://www.deeplearningbook.org/.\n",
        "\n",
        "[3] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting,\" Journal of Machine Learning Research, vol. 15, pp. 1929-1958, 2014. [Online]. Available: http://jmlr.org/papers/v15/srivastava14a.html.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "weCBCHrr3fEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and set variables"
      ],
      "metadata": {
        "id": "MJxAi3OFg-Me"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script sets up a machine learning project for gesture recognition by importing libraries like TensorFlow and sklearn for modeling and data processing, and matplotlib for visualization. It defines constants for data handling and creates directories for organizing models and plots. The gesture dataset is downloadable from GitHub, gets extracted, ensuring data availability and integrity for model training. This very first setup is essential for the project's subsequent data analysis and model development phases."
      ],
      "metadata": {
        "id": "_oWvrVQx34uN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "fda2df46-88dc-470c-c305-2f5e9ca311db",
        "id": "OFHitZM5k6TX"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras_flops'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ee28aecd3251>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_flops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_flops'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.models as tfm\n",
        "import tensorflow.keras.layers as tfl\n",
        "import tensorflow.keras.callbacks as tfc\n",
        "import tensorflow.keras.utils as tfu\n",
        "from tensorflow.keras import regularizers\n",
        "import sklearn.model_selection as skms\n",
        "import sklearn.metrics as skm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import functools\n",
        "import IPython.display as ipd\n",
        "import pandas as pd\n",
        "import io\n",
        "import math\n",
        "import zipfile\n",
        "\n",
        "SEED = 133\n",
        "GesSAMPLES = 119\n",
        "SAMPLERATE = 119\n",
        "MEASTime = 1 / SAMPLERATE\n",
        "GYRO_THRESHOLD = 0.02\n",
        "GRAVITY = 9.81\n",
        "ACC_THRESHOLD = 0.0\n",
        "\n",
        "ADDNOISE = True\n",
        "noiseLVL = 0.1\n",
        "\n",
        "NUMSPELLS = 5\n",
        "STROKELEN = GesSAMPLES + 1\n",
        "LABELS = [\"alohomoraCh\", \"arrestoMCh\", \"avadaCh\", \"locoMCh\", \"revelCh\"]\n",
        "\n",
        "data_set = \"gestures\"\n",
        "\n",
        "# create input/output\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"plots\",  exist_ok=True)\n",
        "os.makedirs(\"gestures\",  exist_ok=True)\n",
        "os.makedirs(\"sets\",  exist_ok=True)\n",
        "\n",
        "!wget https://github.com/th3Flow/mWand/raw/main/python/MovDat.zip\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile('MovDat.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('gestures')  # Specify your destination folder\n",
        "    print(\"Files extracted successfully.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: The file is not a zip file or it is corrupted.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The ZIP file does not exist.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "!rm -rf MovDat.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing the CSV Data"
      ],
      "metadata": {
        "id": "k8UDXazSgVsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment processes and normalizes data from an IMU (Inertial Measurement Unit) for gesture recognition in machine learning. It involves smoothing accelerometer readings with a low-pass filter, calculating velocities and positions, and correcting gyro drift. The data is then normalized across different metrics (acceleration, gyro, degrees, and distance) for consistency. Optionally, noise can be added to simulate real-world conditions. Finally, the processed data is reshaped and split into training and testing sets, making it ready for use in training a neural network model for gesture classification.\n",
        "\n",
        "* Read IMU Data: Extracts accelerometer and gyroscope readings from the IMU sensor.\n",
        "\n",
        "* Apply Low-Pass Filter: Smoothing of the accelerometer data to reduce noise and fluctuations.\n",
        "\n",
        "* Calculate Velocity and Position: Integrating accelerometer data to derive velocity and then position information.\n",
        "\n",
        "* Correct Gyro Drift: Adjusting the gyroscope data to account for any drift over time.\n",
        "\n",
        "* Normalize Data: Scaling of various types of data (acceleration, gyro, degrees, and position) to a consistent range for model input.\n",
        "\n",
        "* Optional Noise Addition: Random noise is introduced to the data to enhance the robustness of the model against real-world measurement noise.\n",
        "\n",
        "* Reshape and Store Processed Data: Convert the processed data into a suitable format for machine learning, typically involving reshaping the data into arrays.\n",
        "\n",
        "* Split Data into Training and Testing Sets: The dataset is divided into training and testing subsets to enable model training and evaluation.\n",
        "\n",
        "* Prepare Data for Machine Learning Model: Ensures that the data is in the correct format and ready for feeding into a machine learning model for gesture recognition training."
      ],
      "metadata": {
        "id": "YFXOv42u6SEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcLDP86s8pFU"
      },
      "outputs": [],
      "source": [
        "def normalize_distance_data(distance_data):\n",
        "\n",
        "    # Normalize the distance data\n",
        "    min_distance = -0.25 #meter\n",
        "    max_distance = 0.25 #meter\n",
        "    normalized_data = (distance_data - min_distance) / (max_distance - min_distance)\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def normalize_gyro_data(gyro_data):\n",
        "\n",
        "    # Normalize the gyro data\n",
        "    min_gyro = -2000 #degree/s\n",
        "    max_gyro = 2000 #degree/s\n",
        "    normalized_data = (gyro_data - min_gyro) / (max_gyro - min_gyro)\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def normalize_degree_data(degree_data):\n",
        "\n",
        "    # Define the known min and max degree values\n",
        "    min_degree = 0\n",
        "    max_degree = 360\n",
        "\n",
        "    # Normalize the degree data\n",
        "    normalized_data = (degree_data - min_degree) / (max_degree - min_degree)\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def normalize_accel_data(accel_data):\n",
        "\n",
        "    min_accel = -4\n",
        "    max_accel = 4\n",
        "\n",
        "    # Normalize the acceleration data\n",
        "    normalized_data = (accel_data - min_accel) / (max_accel - min_accel)\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def process_imu_data(values, last_values, add_noise=False, noise_level=0.01):\n",
        "    # Unpack accelerometer and gyroscope data\n",
        "    ax, ay, az = values[:3]\n",
        "    gx, gy, gz = values[3:6]\n",
        "    # print(values[:3], values[3:6])\n",
        "\n",
        "    # Apply low-pass filter\n",
        "    ax = low_pass_filter(ax, last_values['ax'], 0.5)\n",
        "    ay = low_pass_filter(ay, last_values['ay'], 0.5)\n",
        "    az = low_pass_filter(az, last_values['az'], 0.5)\n",
        "\n",
        "    # Update last accelerometer values\n",
        "    last_values.update({'ax': ax, 'ay': ay, 'az': az})\n",
        "\n",
        "    # Integrate acceleration to get velocity\n",
        "    vx = ax * GRAVITY * MEASTime\n",
        "    vy = ay * GRAVITY * MEASTime\n",
        "    vz = az * GRAVITY * MEASTime\n",
        "\n",
        "    # Integrate velocity to get position\n",
        "    x = last_values['x'] + vx * MEASTime\n",
        "    y = last_values['y'] + vy * MEASTime\n",
        "    z = last_values['z'] + vz * MEASTime\n",
        "\n",
        "\n",
        "    # Update position values\n",
        "    last_values.update({'x': x, 'y': y, 'z': z})\n",
        "\n",
        "    # Correct the gyro drift\n",
        "    rollAcc = fast_atan2(ay*GRAVITY, az*GRAVITY) * (180 / math.pi)\n",
        "    dx = (gx * 0.8) * MEASTime + rollAcc * 0.2\n",
        "\n",
        "    pitchAcc = fast_atan2(ax*GRAVITY, az*GRAVITY) * (180 / math.pi)\n",
        "    dy = (gy * 0.8) * MEASTime + pitchAcc * 0.2\n",
        "\n",
        "    # Apply threshold to gyro z-axis data\n",
        "    dz = 0 if abs(gz) < GYRO_THRESHOLD else gz * MEASTime\n",
        "\n",
        "    #NORMALIZATION\n",
        "    x = normalize_distance_data(x)\n",
        "    y = normalize_distance_data(y)\n",
        "    z = normalize_distance_data(z)\n",
        "\n",
        "    #NORMALIZATION\n",
        "    ax = normalize_accel_data(ax)\n",
        "    ay = normalize_accel_data(ay)\n",
        "    az = normalize_accel_data(az)\n",
        "\n",
        "    #NORMALIZATION\n",
        "    dx = normalize_degree_data(dx)\n",
        "    dy = normalize_degree_data(dy)\n",
        "    dz = normalize_degree_data(dz)\n",
        "\n",
        "    #NORMALIZATION\n",
        "    gx = normalize_gyro_data(gx)\n",
        "    gy = normalize_gyro_data(gy)\n",
        "    gz = normalize_gyro_data(gz)\n",
        "\n",
        "    # Return the processed data\n",
        "    return [ax, ay, az, dx, dy, dz, x, y, z]\n",
        "\n",
        "def low_pass_filter(current_val, previous_val, alpha):\n",
        "\n",
        "    if abs(current_val) < ACC_THRESHOLD:\n",
        "        current_val = 0\n",
        "    return alpha * current_val + (1 - alpha) * previous_val\n",
        "\n",
        "def add_noise_to_imu_data(imu_data, noise_level=0.01):\n",
        "\n",
        "    noise = np.random.normal(0, noise_level, imu_data.shape)\n",
        "    imu_data_noisy = imu_data + noise\n",
        "\n",
        "    return imu_data_noisy\n",
        "\n",
        "def fast_atan2(y, x):\n",
        "    n1 = 0.97239411\n",
        "    n2 = -0.19194795\n",
        "    if x != 0.0:\n",
        "        atan = (math.pi / 4.0) * y / x\n",
        "        z = atan * atan\n",
        "        result = atan * ((n1 + n2 * z) / (1.0 + (n1 + n2) * z))\n",
        "        if x < 0.0:\n",
        "            return result - math.pi if y < 0.0 else result + math.pi\n",
        "    return math.pi / 2.0 if y > 0.0 else -math.pi / 2.0 if y < 0.0 else 0\n",
        "\n",
        "def load_dataset(directory, one_hot=True, seed=SEED, addNOISE=True, noiselvl = noiseLVL):\n",
        "    arrays = []  # Ensure this remains a list\n",
        "    labels = []\n",
        "    label_map = {os.path.basename(filename).split('.')[0]: i for i, filename in enumerate(sorted(glob.glob(f\"{directory}/*.csv\")))}\n",
        "\n",
        "    for file_name in sorted(glob.glob(f\"{directory}/*.csv\")):\n",
        "        gesture_label = label_map[os.path.basename(file_name).split('.')[0]]\n",
        "        with open(file_name, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        lines = lines[1:]  # Skip header\n",
        "        measurement = []\n",
        "        measurement_count = 0\n",
        "        last_values = {'ax': 0, 'ay': 0, 'az': 0, 'x': 0, 'y': 0, 'z': 0}\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip():  # If the line is not empty\n",
        "                values = [float(x) for x in line.strip().split(',')]\n",
        "                processed_data = process_imu_data(values, last_values)\n",
        "\n",
        "                measurement.append(processed_data)\n",
        "                # print(processed_data)\n",
        "            else:\n",
        "                if measurement:  # If there is a measurement, process it\n",
        "\n",
        "                    if addNOISE:\n",
        "                        measurement = add_noise_to_imu_data(np.array(measurement), noiselvl)\n",
        "\n",
        "\n",
        "                    measurement_array = np.array(measurement).reshape(-1)\n",
        "                    arrays.append(measurement_array)  # Append to the list\n",
        "                    labels.append(gesture_label)\n",
        "                    measurement = []  # Reset for the next measurement\n",
        "                    measurement_count += 1\n",
        "                    last_values = {'ax': 0, 'ay': 0, 'az': 0, 'x': 0, 'y': 0, 'z': 0}\n",
        "\n",
        "        if measurement:  # Process the last measurement if it exists\n",
        "\n",
        "            if addNOISE:\n",
        "                        measurement = add_noise_to_imu_data(np.array(measurement), noiselvl)\n",
        "\n",
        "\n",
        "            measurement_array = np.array(measurement).reshape(-1)\n",
        "            arrays.append(measurement_array)  # Append to the list\n",
        "            labels.append(gesture_label)\n",
        "\n",
        "        print(f\"Processing {file_name}: {measurement_count} measurements found.\")\n",
        "\n",
        "    arrays = np.array(arrays)  # Convert the list to a NumPy array here\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    if one_hot:\n",
        "        labels = tfu.to_categorical(labels, num_classes=NUMSPELLS)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = skms.train_test_split(arrays, labels, test_size=0.4, random_state=seed)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data Set and generate Train and Test Data"
      ],
      "metadata": {
        "id": "ulvU6s6724-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_dataset(data_set, SEED, 1, ADDNOISE, noiseLVL)\n",
        "np.save('sets/X_train.npy', X_train)\n",
        "np.save('sets/X_test.npy', X_test)\n",
        "np.save('sets/y_train.npy', y_train)\n",
        "np.save('sets/y_test.npy', y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LJdJTjN3D4C",
        "outputId": "beca4999-08e7-4920-c901-095de8252b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing gestures/alohomoraCh.csv: 45 measurements found.\n",
            "Processing gestures/arrestoMCh.csv: 44 measurements found.\n",
            "Processing gestures/avadaCh.csv: 46 measurements found.\n",
            "Processing gestures/locoMCh.csv: 45 measurements found.\n",
            "Processing gestures/revelCh.csv: 44 measurements found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to replace the training and test datasets properly, just replace X_train, X_test, y_train and y_test. Therefor the function load_dataset can be run again to generate another set of X_train, X_test, y_train as well as y_test to be used again in the collab"
      ],
      "metadata": {
        "id": "ovQXDtHuDFnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the structure of the Neural Network"
      ],
      "metadata": {
        "id": "tulPvT61hS7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Activation Function: A LeakyReLU activation function with a 0.1 negative slope is employed. This function helps to address the issue of \"dying neurons\" in the network.\n",
        "\"Dying neurons\" in neural networks using ReLU activation functions occur when neurons stop learning and only output zeros, becoming inactive due to consistently negative input weights leading to zero gradients during backpropagation.\n",
        "\n",
        "* Model Architecture: The model is a sequential stack of layers, specifically designed to prevent overfitting and enhance learning.\n",
        "\n",
        "The \"sandglass\" structure of the model, characterized by a particular pattern of layer units (71-28-71), suggests a focus on feature extraction and re-expansion. This architecture initially compresses or condenses the input data (narrowing down to 28 units), which can help in extracting essential features. Subsequently, it re-expands these features (back to 71 units), potentially allowing the network to reconstruct or refine these features before making a final classification with the output layer. This design can be effective in capturing complex patterns in data while maintaining a balance between model complexity and generalization."
      ],
      "metadata": {
        "id": "WL7ki4XvAUJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "hidden_activation = tf.keras.layers.LeakyReLU(0.1)\n",
        "dropoutOne = 0.4\n",
        "dropoutTwo = 0.2\n",
        "dropoutThree = 0\n",
        "l2_reg = 0.001  # L2 regularization factor\n",
        "\n",
        "model = tfm.Sequential([\n",
        "    tfl.Dense(units=71, activation=hidden_activation, kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    tfl.Dropout(dropoutOne),\n",
        "    tfl.Dense(units=28, activation=hidden_activation, kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    tfl.Dropout(dropoutTwo),\n",
        "    tfl.Dense(units=71, activation=hidden_activation, kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    tfl.Dropout(dropoutThree),\n",
        "    tfl.Dense(units=NUMSPELLS, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_name = \"FMWandModel\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck0RDRu93DnQ",
        "outputId": "222809b0-7054-4082-920c-9c55fa2aa714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (134, 1071)\n",
            "y_train shape: (134, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimize and train the weights"
      ],
      "metadata": {
        "id": "BhpVCdF1htqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code initiates by setting a consistent random seed for reproducibility across various libraries. It then constructs the model with the defined architecture tailored to the shape of X_train and retrieves its initial weights. A key feature of the training process is the use of an exponential decay learning rate schedule applied to the Adam optimizer, which gradually decreases the learning rate during training. This helps in fine-tuning the model's learning process, potentially leading to better performance and stability. The model is then compiled with categorical cross-entropy as the loss function and accuracy as the metric. For training, the model undergoes 100 epochs with early stopping employed to prevent overfitting, monitoring validation accuracy with a patience of 10 epochs. The model trains on mini-batches of size 8 and uses 40% of the training data for validation. The total number of epochs run, potentially less than 100 due to early stopping, is recorded in the results dictionary for later analysis."
      ],
      "metadata": {
        "id": "9d3h0J_8-wNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# get weights for the given seed\n",
        "model.build(X_train.shape)\n",
        "weights = model.get_weights()\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.4, batch_size=8, verbose=1, callbacks=[tfc.EarlyStopping(monitor=\"val_accuracy\", patience=10, mode=\"max\", restore_best_weights=False)]).history\n",
        "epochs = len(history[\"loss\"])\n",
        "results[\"Epochs\"] = epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyxMIewQE2zD",
        "outputId": "9cf9e8c3-7b42-4493-e695-0338395cd21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 5s 136ms/step - loss: 1.7976 - accuracy: 0.2750 - val_loss: 1.8329 - val_accuracy: 0.1296\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 1.7815 - accuracy: 0.3000 - val_loss: 1.7965 - val_accuracy: 0.1667\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.7592 - accuracy: 0.3375 - val_loss: 1.7036 - val_accuracy: 0.4444\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 1.6462 - accuracy: 0.3750 - val_loss: 1.7258 - val_accuracy: 0.2037\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1.5593 - accuracy: 0.4250 - val_loss: 1.4940 - val_accuracy: 0.7037\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4606 - accuracy: 0.4000 - val_loss: 1.3611 - val_accuracy: 0.6296\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1.4177 - accuracy: 0.5125 - val_loss: 1.3628 - val_accuracy: 0.4815\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1.3327 - accuracy: 0.5375 - val_loss: 1.1003 - val_accuracy: 0.8704\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.0884 - accuracy: 0.6875 - val_loss: 0.9827 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.9514 - accuracy: 0.7375 - val_loss: 0.8452 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8624 - accuracy: 0.7375 - val_loss: 0.7898 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7356 - accuracy: 0.8125 - val_loss: 0.6731 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6374 - accuracy: 0.8750 - val_loss: 0.6303 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5804 - accuracy: 0.9250 - val_loss: 0.5832 - val_accuracy: 0.9074\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5149 - accuracy: 0.9375 - val_loss: 0.5347 - val_accuracy: 0.9444\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5422 - accuracy: 0.9125 - val_loss: 0.5090 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5524 - accuracy: 0.8625 - val_loss: 0.5236 - val_accuracy: 0.9074\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4556 - accuracy: 0.9250 - val_loss: 0.5225 - val_accuracy: 0.9444\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.9500 - val_loss: 0.4918 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4086 - accuracy: 0.9250 - val_loss: 0.4706 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3396 - accuracy: 0.9375 - val_loss: 0.4919 - val_accuracy: 0.9444\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3405 - accuracy: 0.9625 - val_loss: 0.4738 - val_accuracy: 0.9444\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3814 - accuracy: 0.9375 - val_loss: 0.4476 - val_accuracy: 0.9074\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.3174 - accuracy: 0.9750 - val_loss: 0.5191 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.3245 - accuracy: 0.9750 - val_loss: 0.4813 - val_accuracy: 0.9259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the full training Model and compare to GPU"
      ],
      "metadata": {
        "id": "6bmgX-Evhz5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this code, the neural network model's weights are reset to their initial state, ensuring a consistent starting point for training. An exponential decay learning rate schedule is set up for the Adam optimizer, beginning at 0.001 and reducing gradually, to optimize the learning process. The model is then compiled with this optimizer, using categorical cross-entropy for loss and accuracy for evaluation. Training is executed on the entire dataset without a validation split, with the total training time measured and recorded. This approach focuses on maximizing data utilization for training and efficiently tracking training duration, especially relevant for GPU-based training environments."
      ],
      "metadata": {
        "id": "rj32XmlUCbC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(weights)\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "train_start = time.time()\n",
        "model.fit(X_train, y_train, epochs=epochs, validation_split=0.0, batch_size=8, verbose=1)\n",
        "results[\"Training time GPU\"] = f\"{(time.time() - train_start):.2f} s\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZNaEzl4-J2x",
        "outputId": "276f811e-de4f-421c-9047-9a507827fad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "17/17 [==============================] - 5s 11ms/step - loss: 1.8298 - accuracy: 0.2388\n",
            "Epoch 2/25\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.7901 - accuracy: 0.3134\n",
            "Epoch 3/25\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.6944 - accuracy: 0.3881\n",
            "Epoch 4/25\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.5885 - accuracy: 0.4328\n",
            "Epoch 5/25\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.4132 - accuracy: 0.5896\n",
            "Epoch 6/25\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.2627 - accuracy: 0.6194\n",
            "Epoch 7/25\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.9966 - accuracy: 0.7090\n",
            "Epoch 8/25\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.8600 - accuracy: 0.7612\n",
            "Epoch 9/25\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.6916 - accuracy: 0.8507\n",
            "Epoch 10/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.8507\n",
            "Epoch 11/25\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5307 - accuracy: 0.8955\n",
            "Epoch 12/25\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.9179\n",
            "Epoch 13/25\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9328\n",
            "Epoch 14/25\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.8955\n",
            "Epoch 15/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.9328\n",
            "Epoch 16/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.9254\n",
            "Epoch 17/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.9478\n",
            "Epoch 18/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.9627\n",
            "Epoch 19/25\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.9776\n",
            "Epoch 20/25\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.9328\n",
            "Epoch 21/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.9701\n",
            "Epoch 22/25\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.9627\n",
            "Epoch 23/25\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.9776\n",
            "Epoch 24/25\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2514 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2993 - accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Used FLOPS"
      ],
      "metadata": {
        "id": "Clkw1iscHV64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_flops = 0\n",
        "for layer in model.layers:\n",
        "    if type(layer) == tf.keras.layers.Dense:\n",
        "        input_shape = layer.input_shape\n",
        "        output_shape = layer.output_shape\n",
        "        if not layer.use_bias:\n",
        "            # 2 * input_units * output_units for multiply-add operations\n",
        "            flops = 2 * input_shape[1] * output_shape[1]\n",
        "        else:\n",
        "            # Add operations for bias\n",
        "            flops = (2 * input_shape[1] + 1) * output_shape[1]\n",
        "\n",
        "        total_flops += flops\n",
        "\n",
        "print(f\"Total FLOPS: {total_flops}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdd6EHEGHeOm",
        "outputId": "9772439c-1d75-45b4-a738-d99703cb8b8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPS: 160919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert calculated Model to TensorFlowLite"
      ],
      "metadata": {
        "id": "oj26LGcqh-75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code should efficiently convert a TensorFlow Keras model into TensorFlow Lite (TFLite) format, offering both standard and optimized versions. The conversion employs TFLiteConverter, adapting the model for lightweight deployment. The optimized version incorporates quantization and INT8 operations, significantly reducing the model size and potentially boosting inference speed, crucial for resource-constrained environments like mobile or embedded systems. The process includes generating a representative dataset for quantization accuracy. Post-conversion, the models are saved, and their sizes are reported, highlighting the effectiveness of optimization in shrinking the model footprint while maintaining functionality, a key benefit for deployment in limited-resource scenarios."
      ],
      "metadata": {
        "id": "4iN2P-FlTIGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tflite(model, X_train, output_path, optimized=False):\n",
        "    # Setting up the converter\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "    # Apply optimization if needed\n",
        "    if optimized:\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "        converter.inference_input_type = tf.int8\n",
        "        converter.inference_output_type = tf.int8\n",
        "\n",
        "        # Ensure representative_dataset is a callable that returns a generator\n",
        "        converter.representative_dataset = lambda: representative_dataset_generator(X_train)\n",
        "\n",
        "    # Convert the model\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the converted model\n",
        "    model_filename = output_path + (\"_opt\" if optimized else \"\") + \".tflite\"\n",
        "    with open(model_filename, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    return model_filename, tflite_model\n",
        "\n",
        "def representative_dataset_generator(X_train):\n",
        "    for value in X_train:\n",
        "        # Prepare each sample as expected by the model (e.g., reshaping, scaling)\n",
        "        processed_value = np.expand_dims(value, 0).astype(np.float32)\n",
        "        # print(\"Yielding sample:\", processed_value.shape)\n",
        "        yield [processed_value]\n",
        "\n",
        "# Paths for the model files\n",
        "output_path = \"models/model\"\n",
        "model_name = \"mWand Model\"\n",
        "\n",
        "# Convert and save the models\n",
        "model_path, tfModel  = convert_to_tflite(model, X_train, output_path, optimized=False)\n",
        "optimized_model_path, tfModel_opt = convert_to_tflite(model, X_train, output_path, optimized=True)\n",
        "\n",
        "# Print the sizes of the models\n",
        "print(f\"Size of the standard model: {os.path.getsize(model_path)} bytes\")\n",
        "print(f\"Size of the optimized model: {os.path.getsize(optimized_model_path)} bytes\")"
      ],
      "metadata": {
        "id": "9fBWWif7KnoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Performance of the Model"
      ],
      "metadata": {
        "id": "oRSXDdvpiFEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A comprehensive evaluation of both a TensorFlow model and its optimized TensorFlow Lite (TFLite) counterpart. The evaluate_model function first assesses the standard model's accuracy on test data, comparing predicted and actual labels. It then evaluates the optimized TFLite model, handling quantized inputs and outputs to accurately gauge its performance. The process generates accuracies for both models, providing a clear comparison of their effectiveness. This evaluation is particularly useful in balancing the trade-offs between model size and accuracy, a critical consideration in resource-constrained deployment environments like edge computing or mobile devices. By executing and printing these results, the code aids in decision-making for deploying the most efficient model without compromising on performance."
      ],
      "metadata": {
        "id": "4GlwNLlanFG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, optimized_model_path):\n",
        "    results = {}\n",
        "\n",
        "    # Evaluate the full model\n",
        "    predictions_full = model.predict(X_test, verbose=0)\n",
        "    predictions_full = np.argmax(predictions_full, axis=1)\n",
        "    results[\"Full model accuracy\"] = f\"{(np.sum(predictions_full == y_test.argmax(axis=1)) / y_test.shape[0] * 100):.2f} %\"\n",
        "\n",
        "    # Load and evaluate the optimized model\n",
        "    interpreter = tf.lite.Interpreter(model_path=optimized_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    input_scale, input_zero_point = interpreter.get_input_details()[0][\"quantization\"]\n",
        "    output_scale, output_zero_point = interpreter.get_output_details()[0][\"quantization\"]\n",
        "\n",
        "    predictions_opt = np.zeros((y_test.shape[0]))\n",
        "    for i, sample in enumerate(X_test):\n",
        "        sample_quantized = np.expand_dims(sample / input_scale + input_zero_point, 0).astype(np.int8)\n",
        "        interpreter.set_tensor(input_index, sample_quantized)\n",
        "        interpreter.invoke()\n",
        "        predictions_opt[i] = np.argmax(interpreter.get_tensor(output_index)[0])\n",
        "\n",
        "    results[\"Optimized model accuracy\"] = f\"{(np.sum(predictions_opt == y_test.argmax(axis=1)) / y_test.shape[0] * 100):.2f} %\"\n",
        "\n",
        "    return results, predictions_full, predictions_opt, input_scale, input_zero_point, output_scale, output_zero_point"
      ],
      "metadata": {
        "id": "_ABeEC6Ymeo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "results, predictions_full, predictions_opt, input_scale, input_zero_point, output_scale, output_zero_point = evaluate_model(model, X_test, y_test, optimized_model_path)\n",
        "\n",
        "# Print the results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "NLsItKylx_h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate and plot the confusion Matrix"
      ],
      "metadata": {
        "id": "0TdRIAqPiO4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specialized tool for visualizing the performance of an optimized machine learning model, specifically focusing on classification accuracy. It works by first ensuring compatibility with one-hot encoded labels, converting them to class labels if necessary. The core of the function involves generating a confusion matrix that contrasts the model's predictions against actual labels, providing a clear, quantified view of its performance. This matrix is then visualized in an easily interpretable format, using a blue color scheme for clarity. The resulting plot, saved as a high-resolution image, serves as a valuable tool for analyzing the model's strengths and weaknesses in classification tasks, thereby aiding in refining and enhancing the model's accuracy."
      ],
      "metadata": {
        "id": "fm-MXYQnnyft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming LABELS, predictions_full, and predictions_opt are defined as before\n",
        "\n",
        "def plot_confusion_matrix_optimized(y_test, predictions_opt, LABELS):\n",
        "    # Convert one-hot encoded y_test to class labels if necessary\n",
        "    if y_test.ndim > 1 and y_test.shape[1] > 1:\n",
        "        y_test_labels = np.argmax(y_test, axis=1)\n",
        "    else:\n",
        "        y_test_labels = y_test\n",
        "\n",
        "    # Plot the confusion matrix of the optimized model\n",
        "    confusion_matrix = tf.math.confusion_matrix(y_test_labels, predictions_opt).numpy()\n",
        "    display = skm.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=LABELS)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(50, 12))\n",
        "    display.plot(cmap=\"Blues\")\n",
        "    plt.title(\"Optimized Model\")\n",
        "    plt.savefig(\"plots/optimized_model_confusion_matrix.png\", dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your data\n",
        "plot_confusion_matrix_optimized(y_test, predictions_opt, LABELS)"
      ],
      "metadata": {
        "id": "CFDH0f5OlXN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The confusion matrix indicates high accuracy for a five-class optimized model, with most predictions correctly falling on the diagonal. Minor misclassifications are rare, showing the model's robust performance in classifying gestures.\n",
        "\n",
        "The displayed confusion matrix for an optimized model demonstrates excellent predictive performance for gesture recognition, with the majority of gestures such as \"Alohomora\" and \"Revelio\" being accurately identified. There is a slight confusion between \"Alohomora\" and \"Locomotor,\" indicating a small area for improvement. Overall, the model shows strong classification capabilities with minimal errors, here."
      ],
      "metadata": {
        "id": "hbbTMLXkq2g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Header Files for the Hardware"
      ],
      "metadata": {
        "id": "FUSr77wdiYMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we integrate a TensorFlow Lite model with an Arduino-based system. It begins by loading the optimized TensorFlow Lite model from a file, converting its binary data into a C array format. This array is then saved into a header file (model.h), enabling its use in an Arduino environment. Additionally, the snippet creates a second header file (model_params.h) containing essential model parameters like input and output scales and zero points. These parameters are critical for accurate data processing and interpretation in the Arduino context. The inclusion of header guards in model_params.h ensures safe and repeated use across different parts of a C/C++ project. This approach effectively bridges the gap between sophisticated machine learning models and the more constrained environment of microcontrollers, exemplifying how advanced AI techniques can be deployed in embedded systems.\n",
        "\n",
        "The *model_params.h* file in an Arduino project contains critical parameters for a TensorFlow Lite model, specifically focusing on quantization aspects necessary for microcontroller environments. It includes the input scale (input_scale) and zero point (input_zero_point), which are essential for adjusting real-world input data to the model's expected format. Similarly, it stores the output scale (output_scale) and zero point (output_zero_point), crucial for correctly interpreting the model's quantized output. These parameters ensure the data is accurately processed, matching the model's training and quantization specifications for reliable performance in embedded systems."
      ],
      "metadata": {
        "id": "zdH9Nsnmo7EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorFlow Lite model file\n",
        "tflite_model_file = optimized_model_path\n",
        "with open(tflite_model_file, 'rb') as file:\n",
        "    tflite_model = file.read()\n",
        "\n",
        "# Convert the model to a C array\n",
        "c_array = ','.join(map(lambda x: str(x), tflite_model))\n",
        "c_array = f\"unsigned char model[] = {{{c_array}}};\"\n",
        "\n",
        "# Save the C array to a header file\n",
        "with open('model.h', 'w') as file:\n",
        "    file.write(c_array)\n",
        "\n",
        "with open('model_params.h', 'w') as file:\n",
        "    file.write(f\"#ifndef MODEL_PARAMS_H\\n#define MODEL_PARAMS_H\\n\\n\")\n",
        "    file.write(f\"const float input_scale = {input_scale};\\n\")\n",
        "    file.write(f\"const int input_zero_point = {input_zero_point};\\n\")\n",
        "    file.write(f\"const float output_scale = {output_scale};\\n\")\n",
        "    file.write(f\"const int output_zero_point = {output_zero_point};\\n\\n\")\n",
        "    file.write(f\"#endif // MODEL_PARAMS_H\\n\")"
      ],
      "metadata": {
        "id": "akJKRbawrIPM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}